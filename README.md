# ğŸš€ Multi-Model LangChain Chatbot with RAG

![License](https://img.shields.io/badge/License-MIT-blue.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.1.0-blue.svg)
![Multi-Model](https://img.shields.io/badge/Supports-4+_LLM_Providers-green.svg)

A sophisticated chatbot framework integrating multiple AI providers with Retrieval-Augmented Generation (RAG) capabilities, built with LangChain.

## ğŸŒŸ Key Features

- **ğŸ”Œ Multi-Model Support**: OpenAI, Hugging Face, Groq, and local LLMs
- **ğŸ“š RAG Implementation**: Document retrieval and generation
- **ğŸ¤– Agent System**: Autonomous agent capabilities
- **ğŸŒ API Ready**: Built-in FastAPI endpoints
- **ğŸ“Š Multiple Use Cases**: From simple chat to document analysis

## ğŸ§© Supported Models & Integrations

| Provider | Models | Notebook | API |
|----------|--------|----------|-----|
| <img src="https://openai.com/favicon.ico" width="16"> **OpenAI** | GPT-4, GPT-3.5 | [GPT4o_Lanchain_RAG.ipynb](/openai/GPT4o_Lanchain_RAG.ipynb) | âœ… |
| <img src="https://huggingface.co/favicon.ico" width="16"> **Hugging Face** | Various OSS models | [huggingface.ipynb](/huggingface/huggingface.ipynb) | âœ… |
| <img src="https://groq.com/favicon.ico" width="16"> **Groq** | Llama 3, Mixtral | [llama3.py](/groq/llama3.py) | âœ… |
| **Local Models** | Llama.cpp compatible | [localama.py](/chatbot/localama.py) | âœ… |

## ğŸ› ï¸ Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/Hari-Kec/Langchain-Agents.git
   cd Langchain-Agents
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**:
   ```bash
   cp config/.env.example .env
   # Edit .env with your API keys
   ```

## ğŸ—ï¸ Project Structure

```
ğŸ“¦Langchain-RAG-OpenAI-HF
â”œâ”€â”€ ğŸ“‚agents/            # Autonomous agent implementations
â”‚   â””â”€â”€ agents.ipynb
â”œâ”€â”€ ğŸ“‚api/               # FastAPI endpoints
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ client.py
â”œâ”€â”€ ğŸ“‚chain/             # LangChain implementations
â”‚   â”œâ”€â”€ attention.pdf
â”‚   â””â”€â”€ retriever.ipynb
â”œâ”€â”€ ğŸ“‚chatbot/           # Chatbot interfaces
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ localama.py
â”œâ”€â”€ ğŸ“‚groq/              # Groq implementations
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ groq.ipynb
â”‚   â””â”€â”€ llama3.py
â”œâ”€â”€ ğŸ“‚huggingface/       # Hugging Face implementations
â”‚   â”œâ”€â”€ huggingface.ipynb
â”‚   â””â”€â”€ ğŸ“‚us_census/     # Example documents
â”œâ”€â”€ ğŸ“‚objectbox/         # Vector store implementations
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ ğŸ“‚us_census/
â”œâ”€â”€ ğŸ“‚openai/            # OpenAI implementations
â”‚   â””â”€â”€ GPT4o_Lanchain_RAG.ipynb
â”œâ”€â”€ ğŸ“‚rag/               # RAG implementations
â”‚   â”œâ”€â”€ attention.pdf
â”‚   â”œâ”€â”€ simplerag.ipynb
â”‚   â””â”€â”€ speech.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ requirements.txt
```

## ğŸš€ Quick Start

### Running the Chatbot Interface
```bash
streamlit run chatbot/app.py
```

### Starting the API Server
```bash
uvicorn api.app:app --reload
```

### Testing with Different Models

1. **Groq (Llama 3)**:
   ```bash
   python groq/llama3.py
   ```

2. **Local Model**:
   ```bash
   python chatbot/localama.py
   ```

3. **RAG Implementation**:
   ```bash
   jupyter notebook chain/retriever.ipynb
   ```

## ğŸ“š Documentation

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/chat` | POST | Chat with selected model |
| `/rag` | POST | Document-based question answering |
| `/models` | GET | List available models |

Example request:
```python
import requests

response = requests.post(
    "http://localhost:8000/chat",
    json={"model": "groq-llama3", "message": "Explain quantum computing"}
)
```

### Configuration

Edit `config/config.yaml` to:
- Set default model preferences
- Configure RAG parameters
- Adjust chunking strategies

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

We welcome contributions! Please see our [contribution guidelines](CONTRIBUTING.md) for details.

## ğŸ“Š Benchmarks

| Model | Speed (tokens/sec) | Accuracy | Cost |
|-------|-------------------|----------|------|
| Groq-Llama3 | 500+ | 85% | $$ |
| OpenAI GPT-4 | 100 | 92% | $$$$ |
| Local Llama2 | 30 | 78% | $ |

## ğŸ› ï¸ Advanced Features

- **Hybrid Retrieval**: Combine vector search with keyword search
- **Multi-hop QA**: Complex question answering across documents
- **Model Fusion**: Combine outputs from multiple LLMs

## ğŸ“« Contact

For questions or support, please [open an issue](https://github.com/Hari-Kec/Langchain-Agents/issues).
